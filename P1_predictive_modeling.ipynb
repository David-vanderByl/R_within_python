{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling using the Titanic Dataset\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to predict who survived the Titanic disaster. The dataset includes passenger information like age, sex, ticket class, and whether or not they survived.\n",
    "\n",
    "Firstly, you'll need the Titanic dataset. It is available in several places. For our use case, we'll download it from a public GitHub repository using Python's requests library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "data_string = requests.get(url).text\n",
    "data = StringIO(data_string) \n",
    "titanic_df = pd.read_csv(data)\n",
    "\n",
    "titanic_df.to_csv('./data/titanic.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, let's do some data cleaning and feature engineering with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "titanic_df = pd.read_csv('./data/titanic.csv')\n",
    "\n",
    "# Fill missing age data with median values\n",
    "titanic_df['Age'].fillna(titanic_df['Age'].median(), inplace=True)\n",
    "\n",
    "# Convert 'Sex' to a numerical variable (male:0, female:1)\n",
    "titanic_df['Sex'] = titanic_df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Feature engineering: create a new feature 'FamilySize'\n",
    "titanic_df['FamilySize'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1\n",
    "\n",
    "# Drop columns we don't need\n",
    "titanic_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)\n",
    "\n",
    "# Save the cleaned data\n",
    "titanic_df.to_csv('./data/cleaned_titanic.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, we will use R and the `randomForest` package to build a predictive model. We can call R scripts from Python using `rpy2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.8395522\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "\n",
    "# Set the CRAN mirror\n",
    "robjects.r('''\n",
    "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n",
    "''')\n",
    "\n",
    "# Check if the randomForest package is installed\n",
    "if 'randomForest' not in robjects.r('installed.packages()'):\n",
    "    # Install the randomForest package\n",
    "    utils = importr('utils')\n",
    "    utils.install_packages(StrVector(['randomForest']))\n",
    "\n",
    "# Import the randomForest package\n",
    "randomForest = importr(\"randomForest\")\n",
    "\n",
    "# Get the absolute path to the cleaned_titanic.csv file\n",
    "current_dir = os.getcwd()\n",
    "cleaned_titanic_path = os.path.join(current_dir, 'data', 'cleaned_titanic.csv')\n",
    "\n",
    "# Define your R script\n",
    "r_script = f\"\"\"\n",
    "# Load necessary libraries\n",
    "library(randomForest)\n",
    "\n",
    "# Load the data\n",
    "titanic_df <- read.csv('{cleaned_titanic_path}')\n",
    "\n",
    "# Convert 'Survived' to a factor\n",
    "titanic_df$Survived <- as.factor(titanic_df$Survived)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "set.seed(123)\n",
    "train_indices <- sample(1:nrow(titanic_df), nrow(titanic_df)*0.7)\n",
    "train_df <- titanic_df[train_indices, ]\n",
    "test_df <- titanic_df[-train_indices, ]\n",
    "\n",
    "# Build the model\n",
    "rf_model <- randomForest(Survived ~ ., data=train_df, ntree=500, mtry=3, importance=TRUE)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions <- predict(rf_model, test_df)\n",
    "\n",
    "# Evaluate the model\n",
    "conf_matrix <- table(test_df$Survived, predictions)\n",
    "accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)\n",
    "\n",
    "print(accuracy)\n",
    "\"\"\"\n",
    "\n",
    "# Run the R script\n",
    "robjects.r(r_script)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script builds a Random Forest model, uses it to make predictions on the test data, and evaluates the accuracy of these predictions.\n",
    "\n",
    "You may need to install the necessary R packages if you don't have them yet. You can install them in R with `install.packages('randomForest')`. Also, remember that you can get more detailed model evaluation metrics, tune model parameters, and try different models to potentially get better results. This is just a simple demonstration of a data science project involving Python, R, and VS Code. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
